{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b317b75efd19d842",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T22:33:43.256489Z",
     "start_time": "2024-11-27T22:33:42.629596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "2.3.0+cu121\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import logging\n",
    "import secrets\n",
    "import numpy\n",
    "import copy\n",
    "import gc\n",
    "import math\n",
    "from datetime import timedelta\n",
    "# import mplcursors\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "# from IPython.display import display\n",
    "# from IPython.display import Audio\n",
    "from IPython import display\n",
    "\n",
    "import time\n",
    "\n",
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from complexPyTorch.complexFunctions import complex_relu\n",
    "\n",
    "import auraloss\n",
    "\n",
    "# Audio\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from torio.io import CodecConfig\n",
    "\n",
    "# Image datasets and image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as TVM\n",
    "\n",
    "# Image display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b02c0dbc4ad760",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a680190877767773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:42:07.271846Z",
     "start_time": "2024-04-27T22:42:07.269507Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dataset_directory = '/home/jacob/noisy-commonvoice-24k/en/clear'\n",
    "noisy_dataset_directory = '/home/jacob/noisy-commonvoice-24k/en/noisy'\n",
    "models_dir = '/home/jacob/denoise-models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297e913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72dcbe117b485c88",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c92d166f0bc10d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:42:13.525473Z",
     "start_time": "2024-04-27T22:42:11.329523Z"
    }
   },
   "outputs": [],
   "source": [
    "common_voice_dataset = torchaudio.datasets.COMMONVOICE(root=base_dataset_directory)\n",
    "common_voice_noisy_dataset = torchaudio.datasets.COMMONVOICE(root=noisy_dataset_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cfca0e0-033d-4da4-b362-63c99e0aa988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, _ = waveform.shape\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "    figure.suptitle(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabf2f1564f979e",
   "metadata": {},
   "source": [
    "### Load datasets and create train / test splits. The same seed is used for splitting noisy and clear datasets so the files match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862c1774d190c8b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T05:48:44.728357Z",
     "start_time": "2024-12-02T05:48:44.661619Z"
    }
   },
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "\n",
    "loader_batch_size = 1\n",
    "loader_num_workers = 4\n",
    "\n",
    "split_generator_0 = torch.Generator().manual_seed(314)\n",
    "noisy_train, noisy_test = random_split(common_voice_dataset, [0.9, 0.1], generator=split_generator_0)\n",
    "\n",
    "split_generator_1 = torch.Generator().manual_seed(314)\n",
    "clear_train, clear_test = random_split(common_voice_noisy_dataset, [0.9, 0.1], generator=split_generator_1)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # print(f\"Collating batch size {len(batch)}\")\n",
    "    \n",
    "    # Extract the tensors from the batch\n",
    "    tensors = [item[0] for item in batch]\n",
    "    tensors = [item.permute(1, 0) for item in tensors]\n",
    "    \n",
    "    # Pad the tensors to the same length\n",
    "    padded_tensors = torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True, padding_value=0)\n",
    "    \n",
    "    padded_tensors = [item.permute(1, 0) for item in padded_tensors]\n",
    "        \n",
    "    for i, tensor in enumerate(padded_tensors):\n",
    "        batch[i] = tensor\n",
    "\n",
    "    # print(f\"Returning batch size {len(batch)}\")\n",
    "\n",
    "    return batch\n",
    "\n",
    "clear_generator = torch.Generator()\n",
    "clear_generator.manual_seed(315)\n",
    "\n",
    "clear_loader = DataLoader(\n",
    "    noisy_train,\n",
    "    batch_size=loader_batch_size,\n",
    "    num_workers=loader_num_workers,\n",
    "    pin_memory=True,\n",
    "    pin_memory_device=device,\n",
    "    generator=clear_generator,\n",
    "    # collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "noisy_generator = torch.Generator()\n",
    "noisy_generator.manual_seed(315)\n",
    "\n",
    "noisy_loader = DataLoader(\n",
    "    clear_train,\n",
    "    batch_size=loader_batch_size,\n",
    "    num_workers=loader_num_workers,\n",
    "    pin_memory=True,\n",
    "    pin_memory_device=device,\n",
    "    generator=noisy_generator,\n",
    "    # collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# noisy_1 = next(iter(noisy_train))\n",
    "# clear_1 = next(iter(clear_train))\n",
    "\n",
    "# Audio(noisy_1[0].squeeze(), rate=48000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b18c9e-6909-4c0a-9b96-fdeda195eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(clear_1[0].squeeze(), rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e08810366743b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004e423a-c8ab-4fc1-80bb-37e375d722f4",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_params: 38967673\n",
      "UNet1d(\n",
      "  (first_layer): ConvBlock(\n",
      "    (sequential): Sequential(\n",
      "      (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (down_layers_module_list): ModuleList(\n",
      "    (0): Down(\n",
      "      (sequential): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): ConvBlock(\n",
      "          (sequential): Sequential(\n",
      "            (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Down(\n",
      "      (sequential): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): ConvBlock(\n",
      "          (sequential): Sequential(\n",
      "            (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Down(\n",
      "      (sequential): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): ConvBlock(\n",
      "          (sequential): Sequential(\n",
      "            (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Down(\n",
      "      (sequential): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): ConvBlock(\n",
      "          (sequential): Sequential(\n",
      "            (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (upWithLSTM): UpWithLSTM(\n",
      "    (pre_lstm_reduction): Conv1d(1024, 600, kernel_size=(2,), stride=(2,))\n",
      "    (lstm): LSTM(300, 2400, batch_first=True)\n",
      "    (lstm_downsample): Conv1d(600, 600, kernel_size=(2,), stride=(2,))\n",
      "    (lstm_expansion): Conv1d(600, 512, kernel_size=(1,), stride=(1,))\n",
      "    (transpose): ConvTranspose1d(1024, 512, kernel_size=(2,), stride=(2,))\n",
      "    (convBlock): ConvBlock(\n",
      "      (sequential): Sequential(\n",
      "        (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_layers_module_list): ModuleList(\n",
      "    (0): Up(\n",
      "      (transpose): ConvTranspose1d(512, 256, kernel_size=(2,), stride=(2,))\n",
      "      (convBlock): ConvBlock(\n",
      "        (sequential): Sequential(\n",
      "          (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Up(\n",
      "      (transpose): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,))\n",
      "      (convBlock): ConvBlock(\n",
      "        (sequential): Sequential(\n",
      "          (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (last_layer): OutLayer(\n",
      "    (sequential): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode='linear')\n",
      "      (1): ConvBlock(\n",
      "        (sequential): Sequential(\n",
      "          (0): Conv1d(128, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (4): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### Create a model\n",
    "\n",
    "sample_rate = 24000\n",
    "\n",
    "sample_batch_ms = 400\n",
    "hidden_size_ms = 600\n",
    "\n",
    "samples_per_batch = int((sample_batch_ms / 1000) * sample_rate)\n",
    "samples_per_hidden = int((hidden_size_ms / 1000) * sample_rate)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class ComplexRelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexRelu, self).__init__()\n",
    "             \n",
    "    def forward(self, x):\n",
    "        x = complex_relu(x)\n",
    "        return x\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device, dtype):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, device=device, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=out_channels, device=device, dtype=dtype),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, device=device, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=out_channels, device=device, dtype=dtype),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device, dtype):\n",
    "        super(Down, self).__init__()\n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ConvBlock(in_channels=in_channels, out_channels=out_channels, device=device, dtype=dtype)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "    \n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device, dtype):\n",
    "        super(Up, self).__init__()\n",
    "        \n",
    "        self.transpose = nn.ConvTranspose1d(in_channels=in_channels, out_channels=in_channels // 2, kernel_size=2, stride=2, device=device, dtype=dtype)\n",
    "        self.convBlock = ConvBlock(in_channels=in_channels, out_channels=out_channels, device=device, dtype=dtype)\n",
    "        \n",
    "    def forward(self, x1, x2):        \n",
    "        x1 = self.transpose(x1)\n",
    "        \n",
    "        diff = x2.size()[1] - x1.size()[1]  # Calculate difference correctly\n",
    "        # print(f\"Transposed x1: {x1.size()} x2: {x2.size()} diff: {diff}\")\n",
    "        \n",
    "        # Pad x1 if necessary\n",
    "        x1 = nnF.pad(x1, (diff // 2, diff - diff // 2))\n",
    "        # print(f\"Padded x1: {x1.size()}\")\n",
    "    \n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        # print(f\"Concatenated x: {x.size()}\")\n",
    "        \n",
    "        x = self.convBlock(x)\n",
    "        \n",
    "        # print(f\"ConvBlock output: \\n{x.size()}\")\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class UpWithLSTM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, layer_sizes, device, dtype):\n",
    "        super(UpWithLSTM, self).__init__()\n",
    "        \n",
    "        lstm_input_size = samples_per_batch\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            lstm_input_size = lstm_input_size // 2\n",
    "        \n",
    "        self.pre_lstm_reduction = nn.Conv1d(in_channels=in_channels, out_channels=lstm_input_size, kernel_size=2, stride=2, device=device, dtype=dtype)\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_size // 2, hidden_size=lstm_input_size * 4, num_layers=1, batch_first=True, device=device, dtype=dtype)\n",
    "        # self.lstm_channel_reduction = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, device=device, dtype=dtype)\n",
    "        self.lstm_downsample = nn.Conv1d(in_channels=lstm_input_size, out_channels=lstm_input_size, kernel_size=2, stride=2, device=device, dtype=dtype)\n",
    "        self.lstm_expansion = nn.Conv1d(in_channels=lstm_input_size, out_channels=out_channels, kernel_size=1, stride=1, device=device, dtype=dtype)\n",
    "        \n",
    "        self.transpose = nn.ConvTranspose1d(in_channels=in_channels, out_channels=in_channels // 2, kernel_size=2, stride=2, device=device, dtype=dtype)\n",
    "        self.convBlock = ConvBlock(in_channels=in_channels, out_channels=out_channels, device=device, dtype=dtype)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        # print(f\"UPPPPPP x1 size: {x1.size()} x2 size: {x2.size()} x3 size: {x3.size()}\")\n",
    "        \n",
    "        # print(f\"x1 before LSTM: {x1.size()}\")\n",
    "        lstm_out = self.pre_lstm_reduction(x1)\n",
    "        # print(f\"Pre-LSTM output: {lstm_out.size()}\")\n",
    "        lstm_out = self.lstm(lstm_out)[0]\n",
    "        # print(f\"LSTM output: {lstm_out.size()}\")        \n",
    "        # lstm_out = self.lstm_channel_reduction(lstm_out)\n",
    "        # print(f\"LSTM lstm_channel_reduction output: {lstm_out.size()}\")\n",
    "        lstm_out = self.lstm_downsample(lstm_out)\n",
    "        # print(f\"LSTM lstm_downsample output: {lstm_out.size()}\")\n",
    "        lstm_out = self.lstm_expansion(lstm_out)\n",
    "        # print(f\"LSTM lstm_expansion output: {lstm_out.size()}\")\n",
    "        \n",
    "        x1 = self.transpose(x1)\n",
    "                \n",
    "        diff = x2.size()[1] - x1.size()[1]  # Calculate difference correctly\n",
    "        # print(f\"Transposed x1: {x1.size()} x2: {x2.size()} diff: {diff}\")\n",
    "        \n",
    "        # Pad x1 if necessary\n",
    "        x1 = nnF.pad(x1, (diff // 2, diff - diff // 2))\n",
    "        # print(f\"Padded x1: {x1.size()}\")\n",
    "        \n",
    "        # print(f\"x1: {x1}, lstm: {lstm_out}\")        \n",
    "        x1 = x1 + lstm_out\n",
    "    \n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        # print(f\"Concatenated x: {x.size()}\")\n",
    "        \n",
    "        \n",
    "        x = self.convBlock(x)\n",
    "        \n",
    "        # print(f\"ConvBlock output: \\n{x.size()}\")\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class OutLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device, dtype):\n",
    "        super(OutLayer, self).__init__()\n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='linear', align_corners=True),\n",
    "            ConvBlock(in_channels=in_channels, out_channels=out_channels, device=device, dtype=dtype),            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "class UNet1d(nn.Module):\n",
    "    def __init__(self, in_channels, device, dtype):\n",
    "        super(UNet1d, self).__init__()\n",
    "        \n",
    "        layer_sizes = [64, 128, 256, 512, 1024]\n",
    "        \n",
    "        self.first_layer = ConvBlock(in_channels=in_channels, out_channels=layer_sizes[0], device=device, dtype=dtype)\n",
    "        \n",
    "        self.down_layers = [\n",
    "            Down(in_channels=layer_sizes[i], out_channels=layer_sizes[i+1], device=device, dtype=dtype)\n",
    "            for i in range(len(layer_sizes) - 1)\n",
    "        ]\n",
    "        self.down_layers_module_list = nn.ModuleList(self.down_layers)\n",
    "                            \n",
    "        self.upWithLSTM = UpWithLSTM(in_channels=layer_sizes[-1], out_channels=layer_sizes[-2], layer_sizes=layer_sizes, device=device, dtype=dtype)\n",
    "        self.remaining_up_layers = [\n",
    "            Up(in_channels=layer_sizes[-(i+2)], out_channels=layer_sizes[-(i+3)], device=device, dtype=dtype)\n",
    "            for i in range(len(layer_sizes) - 3)\n",
    "        ]\n",
    "        self.up_layers_module_list = nn.ModuleList(self.remaining_up_layers)\n",
    "        \n",
    "        self.last_layer = OutLayer(in_channels=layer_sizes[1], out_channels=in_channels, device=device, dtype=dtype)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = x.unsqueeze(0)\n",
    "        \n",
    "        # print(f\"Unsqueezed input: \\n{x.size()}\")     \n",
    "        \n",
    "        x = self.first_layer(x)\n",
    "        \n",
    "        # print(f\"First layer output: \\n{x}\")\n",
    "\n",
    "        # print(f\"after first layer x: {x}\")\n",
    "        down_outputs = []\n",
    "        for down_layer in self.down_layers:\n",
    "            x = down_layer(x)\n",
    "            # print(f\"after down layer x: {x}\")\n",
    "            # print(f\"Down layer output: \\n{x.size()}\")\n",
    "            down_outputs.append(x)\n",
    "            \n",
    "        down_outputs_reversed = list(reversed(down_outputs))\n",
    "                \n",
    "        x = self.upWithLSTM(x, down_outputs_reversed[1])\n",
    "        # print(f\"after up with lstm x: {x.size()}\")\n",
    "        \n",
    "        for (i, up_layer) in enumerate(self.remaining_up_layers):\n",
    "            x = up_layer(x, down_outputs_reversed[i + 2])\n",
    "            # print(f\"after up layer x: {x}\")\n",
    "            # print(f\"Up layer output: \\n{x.size()}\")\n",
    "        \n",
    "        x = self.last_layer(x)\n",
    "        # print(f\"after last layer x: {x}\")\n",
    "\n",
    "        # print(f\"Last layer output: \\n{x.size()}\")\n",
    "        \n",
    "        x = x.squeeze(0).squeeze(0)\n",
    "        # print(f\"after squeeze x: {x}\")\n",
    "        \n",
    "        # print(f\"Squeezed output: \\n{x.size()}\")\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    torch.cuda.empty_cache()\n",
    "    dtype=torch.float32\n",
    "\n",
    "    model_dict_path = models_dir + \"/model-20241207-011427\"\n",
    "    \n",
    "    sequence_model = UNet1d(in_channels=1, device=device, dtype=dtype)\n",
    "    sequence_model.load_state_dict(torch.load(model_dict_path, weights_only=True))\n",
    "    sequence_model.eval()\n",
    "    \n",
    "    total_params = sum(p.numel() for p in sequence_model.parameters())\n",
    "\n",
    "    print(f\"total_params: {total_params}\")    \n",
    "    \n",
    "    loss_fn = nn.L1Loss()\n",
    "    # loss_fn = auraloss.time.SNRLoss()\n",
    "    loss_fn_2 = auraloss.time.SISDRLoss()\n",
    "    # loss_fn_2 = nn.L1Loss()\n",
    "    loss_fn_3 = auraloss.freq.MelSTFTLoss(sample_rate=sample_rate, n_mels=128, device=device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(params=sequence_model.parameters(), lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.006, end_factor=0.004, total_iters=100000)\n",
    "    \n",
    "    print(sequence_model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1ff1b-b4ad-40cd-8f28-25f96a137175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e4c96e3-0eea-4897-a54b-8030dd3361e2",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception in thread Thread-5 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "<bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7203edd73920>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jacob/jupyter-venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    self.run()\n",
      "  File \"/home/jacob/jupyter-venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "Exception in thread Thread-6 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jacob/jupyter-venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "    self.run()\n",
      "  File \"/home/jacob/jupyter-venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    do_one_step()\n",
      "  File \"/home/jacob/jupyter-venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jacob/jupyter-venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacob/jupyter-venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
      "    do_one_step()\n",
      "  File \"/home/jacob/jupyter-venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacob/jupyter-venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 526, in Client\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 938, in deliver_challenge\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "    connection.send_bytes(_CHALLENGE + message)\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 427, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 384, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 2591717, 2591741, 2591765, 2591789) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/jupyter-venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/usr/lib/python3.12/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:66\u001b[0m\n",
      "File \u001b[0;32m~/jupyter-venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/jupyter-venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter-venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/jupyter-venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 2591717, 2591741, 2591765, 2591789) exited unexpectedly"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255e901f97104cefaa7614bb5ce750d4",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "### Train\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "last_short_update_at = None\n",
    "\n",
    "short_update = 100\n",
    "long_update = 200\n",
    "very_long_update = 1000\n",
    "\n",
    "noisy_loader_iter = iter(noisy_loader)\n",
    "clear_loader_iter = iter(clear_loader)\n",
    "epoch_count = 0\n",
    "files_processed_at_last_short_update = 0\n",
    "\n",
    "# custom_batching_size = 3\n",
    "samples_per_iteration = 24000 * 44\n",
    "\n",
    "figdisplay = display.display(\"\", display_id=True)\n",
    "fig, axs = plt.subplots(1, 1, layout='constrained')\n",
    "axs.set_xlabel('Time')\n",
    "axs.set_ylabel('Loss')\n",
    "\n",
    "# Add hover annotations\n",
    "# cursor = mplcursors.cursor(axs, hover=True)\n",
    "# cursor.connect(\"add\", lambda sel: sel.annotation.set_text(f\"Loss: {loss_numbers[sel.index]:.2f}\\nTime: {loss_times[sel.index]:.2f}\"))\n",
    "\n",
    "loss_numbers = []\n",
    "loss_numbers_short_update = []\n",
    "loss_times = []\n",
    "\n",
    "noisy_display = display.display(\"\", display_id=True)\n",
    "prediction_display = display.display(\"\", display_id=True)\n",
    "clear_display = display.display(\"\", display_id=True)\n",
    "\n",
    "status_string_display = display.display(\"\", display_id=True)\n",
    "last_save_status_string_display = display.display(\"\", display_id=True)\n",
    "last_few_loss_display = display.display(\"\", display_id=True)\n",
    "specific_loss_display = display.display(\"\", display_id=True)\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    # restart around the same place in the dataset after an OOM\n",
    "    # for i in range(417000 // custom_batching_size):\n",
    "    #     noisy_batch = [next(noisy_loader_iter)]\n",
    "    #     clear_batch = [next(clear_loader_iter)]\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    remaining_noisy_samples = None\n",
    "    remaining_clear_samples = None\n",
    "    \n",
    "    # print(\"torch.cuda.memory_reserved 1: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "    \n",
    "    while(True):\n",
    "        if remaining_noisy_samples is not None:\n",
    "            noisy = remaining_noisy_samples\n",
    "            clear = remaining_clear_samples\n",
    "            remaining_noisy_samples = None\n",
    "            remaining_clear_samples = None\n",
    "        else:                    \n",
    "            noisy = next(noisy_loader_iter)[0].squeeze(0).squeeze(0).to(device)\n",
    "            clear = next(clear_loader_iter)[0].squeeze(0).squeeze(0).to(device)\n",
    "            files_processed += 1\n",
    "            \n",
    "        # print(\"torch.cuda.memory_reserved 2: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        \n",
    "        while noisy.size()[0] < samples_per_iteration:\n",
    "            noisy = torch.cat((noisy, next(noisy_loader_iter)[0].squeeze(0).squeeze(0).to(device)), dim=0)\n",
    "            clear = torch.cat((clear, next(clear_loader_iter)[0].squeeze(0).squeeze(0).to(device)), dim=0)\n",
    "            files_processed += 1\n",
    "            \n",
    "        # print(\"torch.cuda.memory_reserved 3: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        \n",
    "        noisy_limited = noisy[:samples_per_iteration]\n",
    "        clear_limited = clear[:samples_per_iteration]\n",
    "\n",
    "        # print(f\"noisy_limited 1: {noisy_limited}\")\n",
    "        \n",
    "        if noisy.size()[0] > samples_per_iteration:\n",
    "            remaining_noisy_samples = noisy[samples_per_iteration:]\n",
    "            remaining_clear_samples = clear[samples_per_iteration:]\n",
    "            print(f\"samples_per_batch: {samples_per_batch}: Saving {remaining_noisy_samples.size()[0]} for next round\")\n",
    "\n",
    "        del noisy, clear\n",
    "\n",
    "        # print(\"torch.cuda.memory_reserved 4: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "                \n",
    "        noisy_subsamples = torch.split(noisy_limited, samples_per_batch)\n",
    "        clear_subsamples = torch.split(clear_limited, samples_per_batch)\n",
    "        \n",
    "        noisy_subsamples = torch.stack(noisy_subsamples).unsqueeze(1)\n",
    "        clear_subsamples = torch.stack(clear_subsamples).unsqueeze(1)        \n",
    "\n",
    "        print(f\"noisy_subsamples.size(): {noisy_subsamples.size()}\")\n",
    "\n",
    "        if not (epoch_count % long_update == 0):\n",
    "            del noisy_limited, clear_limited\n",
    "        \n",
    "        loss_sum = 0\n",
    "        \n",
    "        # gc.collect()        \n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "        # print(\"torch.cuda.memory_reserved 6: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        \n",
    "        sequence_model.train()\n",
    "        \n",
    "        prediction = sequence_model(noisy_subsamples)\n",
    "        \n",
    "        if epoch_count % long_update == 0:\n",
    "            prediction_cpu = prediction.cpu()\n",
    "        else:\n",
    "            prediction_cpu = None\n",
    "\n",
    "        loss_1 = loss_fn(prediction, clear_subsamples)\n",
    "        loss_2 = loss_fn_2(prediction, clear_subsamples)\n",
    "        loss_3 = (loss_fn_3(prediction, clear_subsamples) / 3)\n",
    "        # loss_4 = loss_fn_4(prediction, clear_subsamples)\n",
    "        \n",
    "        loss = loss_1 + loss_2 + loss_3\n",
    "        loss_numbers_short_update.append(loss.item())\n",
    "\n",
    "        specific_loss_string = f\"loss_1: {loss_1} loss_2: {loss_2} loss_3: {loss_3}\"\n",
    "\n",
    "        # print(\"torch.cuda.memory_reserved 7: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        \n",
    "        del prediction, noisy_subsamples, clear_subsamples\n",
    "        # gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "        \n",
    "        # print(\"torch.cuda.memory_reserved 8: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # print(\"torch.cuda.memory_reserved 9: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        \n",
    "        del loss, loss_1, loss_2, loss_3\n",
    "        # gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        sequence_model.eval()\n",
    "        \n",
    "        # print(\"torch.cuda.memory_reserved 10: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        \n",
    "        # gc.collect()        \n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "        if epoch_count % short_update == 0 and epoch_count != 0:\n",
    "            now = time.time()\n",
    "            elapsed_str = str(timedelta(seconds=now - t0))\n",
    "            files_per_second = float(files_processed - files_processed_at_last_short_update) / (now - last_short_update_at if last_short_update_at else now - t0) \n",
    "            status_string_display.update(f\"elapsed: {elapsed_str} files_processed: {files_processed} files_per_second: {files_per_second}\")\n",
    "            last_short_update_at = time.time()\n",
    "            files_processed_at_last_short_update = files_processed\n",
    "            \n",
    "            elapsed_seconds = timedelta(seconds=now - t0).total_seconds()\n",
    "            \n",
    "            avg_loss = sum(loss_numbers_short_update) / len(loss_numbers_short_update)\n",
    "            loss_numbers_short_update = []\n",
    "            \n",
    "            loss_times.append(elapsed_seconds)\n",
    "            loss_numbers.append(avg_loss)\n",
    "            \n",
    "            # Plot loss data\n",
    "            # todo: performant sliding window update lines?\n",
    "            plt.plot(loss_times, loss_numbers)\n",
    "\n",
    "            last_few_loss_avgs = loss_numbers[-10:]\n",
    "            last_few_loss_display.update(f\"Last few loss averages: {last_few_loss_avgs}\")\n",
    "\n",
    "            specific_loss_display.update(specific_loss_string)\n",
    "            \n",
    "            plt.autoscale(tight=True)\n",
    "\n",
    "            figdisplay.update(fig)\n",
    "            fig.canvas.draw()\n",
    "\n",
    "            if epoch_count > 3000:\n",
    "                short_update = 400\n",
    "\n",
    "        if epoch_count % long_update == 0:\n",
    "            if prediction_cpu is not None:\n",
    "                noisy_display.update(display.Audio(noisy_limited.cpu().detach(), rate=sample_rate))\n",
    "                prediction_reconstructed = prediction_cpu.view(25, -1).view(1, -1)\n",
    "                prediction_display.update(display.Audio(prediction_reconstructed.cpu().detach(), rate=sample_rate))\n",
    "                clear_display.update(display.Audio(clear_limited.cpu().detach(), rate=sample_rate))\n",
    "            else:\n",
    "                print(f\"prediction_cpu is None!\")\n",
    "\n",
    "        if epoch_count % very_long_update == 0 and epoch_count != 0:\n",
    "            model_save_path = models_dir + f\"/model-{time.strftime(\"%Y%m%d-%H%M%S\")}\"\n",
    "            last_save_status_string_display.update(f\"Saving model to {model_save_path}\")\n",
    "            torch.save(sequence_model.state_dict(), model_save_path)\n",
    "\n",
    "        epoch_count += 1\n",
    "\n",
    "        # print(\"torch.cuda.memory_reserved 11: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        \n",
    "        # gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "        \n",
    "        # print(f\"**** Training iteration complete ****\")\n",
    "        \n",
    "        # print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        # print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        # print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c09e13-bce6-4243-b695-fc80b2956aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
