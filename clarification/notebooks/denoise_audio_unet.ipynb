{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b317b75efd19d842",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T22:33:43.256489Z",
     "start_time": "2024-11-27T22:33:42.629596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "2.3.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import logging\n",
    "import secrets\n",
    "import numpy\n",
    "import copy\n",
    "import gc\n",
    "import math\n",
    "from datetime import timedelta\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "\n",
    "import time\n",
    "\n",
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from complexPyTorch.complexFunctions import complex_relu\n",
    "\n",
    "import auraloss\n",
    "\n",
    "# Audio\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from torio.io import CodecConfig\n",
    "\n",
    "# Image datasets and image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as TVM\n",
    "\n",
    "# Image display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b02c0dbc4ad760",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a680190877767773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:42:07.271846Z",
     "start_time": "2024-04-27T22:42:07.269507Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dataset_directory = '/home/jacob/cv-corpus-17.0-2024-03-15/en'\n",
    "noisy_dataset_directory = '/home/jacob/noisy-commonvoice/en'\n",
    "models_dir = '/home/jacob/denoise-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dcbe117b485c88",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80c92d166f0bc10d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:42:13.525473Z",
     "start_time": "2024-04-27T22:42:11.329523Z"
    }
   },
   "outputs": [],
   "source": [
    "common_voice_dataset = torchaudio.datasets.COMMONVOICE(root=base_dataset_directory)\n",
    "common_voice_noisy_dataset = torchaudio.datasets.COMMONVOICE(root=noisy_dataset_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cfca0e0-033d-4da4-b362-63c99e0aa988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, _ = waveform.shape\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "    figure.suptitle(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabf2f1564f979e",
   "metadata": {},
   "source": [
    "### Load datasets and create train / test splits. The same seed is used for splitting noisy and clear datasets so the files match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "862c1774d190c8b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T22:46:31.938391Z",
     "start_time": "2024-04-27T22:44:38.020628Z"
    }
   },
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "\n",
    "clear_loader = DataLoader(\n",
    "    common_voice_dataset,\n",
    "    batch_size=1)\n",
    "\n",
    "noisy_loader = DataLoader(\n",
    "    common_voice_noisy_dataset,\n",
    "    batch_size=1)\n",
    "\n",
    "split_generator_0 = torch.Generator().manual_seed(314)\n",
    "noisy_train, noisy_test = random_split(noisy_loader.dataset, [0.9, 0.1], generator=split_generator_0)\n",
    "\n",
    "split_generator_1 = torch.Generator().manual_seed(314)\n",
    "clear_train, clear_test = random_split(clear_loader.dataset, [0.9, 0.1], generator=split_generator_1)\n",
    "\n",
    "# noisy_1 = next(iter(noisy_train))\n",
    "# clear_1 = next(iter(clear_train))\n",
    "\n",
    "# Audio(noisy_1[0].squeeze(), rate=48000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b18c9e-6909-4c0a-9b96-fdeda195eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(clear_1[0].squeeze(), rate=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e08810366743b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "004e423a-c8ab-4fc1-80bb-37e375d722f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:59:08.641579Z",
     "start_time": "2024-11-27T23:59:08.572320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet1d(\n",
      "  (first_layer): ConvBlock(\n",
      "    (sequential): Sequential(\n",
      "      (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (down_layers_module_list): ModuleList(\n",
      "    (0): Down(\n",
      "      (sequential): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): ConvBlock(\n",
      "          (sequential): Sequential(\n",
      "            (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Down(\n",
      "      (sequential): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): ConvBlock(\n",
      "          (sequential): Sequential(\n",
      "            (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Down(\n",
      "      (sequential): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): ConvBlock(\n",
      "          (sequential): Sequential(\n",
      "            (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Down(\n",
      "      (sequential): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): ConvBlock(\n",
      "          (sequential): Sequential(\n",
      "            (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_layers_module_list): ModuleList(\n",
      "    (0): Up(\n",
      "      (transpose): ConvTranspose1d(1024, 512, kernel_size=(2,), stride=(2,))\n",
      "      (convBlock): ConvBlock(\n",
      "        (sequential): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Up(\n",
      "      (transpose): ConvTranspose1d(512, 256, kernel_size=(2,), stride=(2,))\n",
      "      (convBlock): ConvBlock(\n",
      "        (sequential): Sequential(\n",
      "          (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Up(\n",
      "      (transpose): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,))\n",
      "      (convBlock): ConvBlock(\n",
      "        (sequential): Sequential(\n",
      "          (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (last_layer): OutLayer(\n",
      "    (sequential): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode='linear')\n",
      "      (1): ConvBlock(\n",
      "        (sequential): Sequential(\n",
      "          (0): Conv1d(128, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (4): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### Create a model\n",
    "\n",
    "sample_rate = 48000\n",
    "\n",
    "sample_batch_ms = 50\n",
    "hidden_size_ms = 200\n",
    "\n",
    "samples_per_batch = int((sample_batch_ms / 1000) * sample_rate)\n",
    "samples_per_hidden = int((hidden_size_ms / 1000) * sample_rate)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class ComplexRelu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexRelu, self).__init__()\n",
    "             \n",
    "    def forward(self, x):\n",
    "        x = complex_relu(x)\n",
    "        return x\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device, dtype):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, device=device, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=out_channels, device=device, dtype=dtype),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, device=device, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=out_channels, device=device, dtype=dtype),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device, dtype):\n",
    "        super(Down, self).__init__()\n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ConvBlock(in_channels=in_channels, out_channels=out_channels, device=device, dtype=dtype)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "    \n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device, dtype):\n",
    "        super(Up, self).__init__()\n",
    "        \n",
    "        self.transpose = nn.ConvTranspose1d(in_channels=in_channels, out_channels=in_channels // 2, kernel_size=2, stride=2, device=device, dtype=dtype)\n",
    "        self.convBlock = ConvBlock(in_channels=in_channels, out_channels=out_channels, device=device, dtype=dtype)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        # print(f\"x1 size: {x1.size()}\")\n",
    "        \n",
    "        x1 = self.transpose(x1)\n",
    "        \n",
    "        diff = x2.size()[1] - x1.size()[1]  # Calculate difference correctly\n",
    "        # print(f\"Transposed x1: {x1.size()} x2: {x2.size()} diff: {diff}\")\n",
    "        \n",
    "        # Pad x1 if necessary\n",
    "        x1 = nnF.pad(x1, (diff // 2, diff - diff // 2))\n",
    "        # print(f\"Padded x1: {x1.size()}\")\n",
    "    \n",
    "        # Concatenate along the channel dimension\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        # print(f\"Concatenated x: {x.size()}\")\n",
    "        \n",
    "        x = self.convBlock(x)\n",
    "        \n",
    "        # print(f\"ConvBlock output: \\n{x.size()}\")\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class OutLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, device, dtype):\n",
    "        super(OutLayer, self).__init__()\n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='linear', align_corners=True),\n",
    "            ConvBlock(in_channels=in_channels, out_channels=out_channels, device=device, dtype=dtype),            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "class UNet1d(nn.Module):\n",
    "    def __init__(self, in_channels, device, dtype):\n",
    "        super(UNet1d, self).__init__()\n",
    "        \n",
    "        layer_sizes = [64, 128, 256, 512, 1024]\n",
    "        \n",
    "        self.first_layer = ConvBlock(in_channels=in_channels, out_channels=layer_sizes[0], device=device, dtype=dtype)\n",
    "        \n",
    "        self.down_layers = [\n",
    "            Down(in_channels=layer_sizes[i], out_channels=layer_sizes[i+1], device=device, dtype=dtype)\n",
    "            for i in range(len(layer_sizes) - 1)\n",
    "        ]\n",
    "        \n",
    "        self.down_layers_module_list = nn.ModuleList(self.down_layers)\n",
    "        \n",
    "        self.up_layers = [\n",
    "            Up(in_channels=layer_sizes[-(i+1)], out_channels=layer_sizes[-(i+2)], device=device, dtype=dtype)\n",
    "            for i in range(len(layer_sizes) - 2)\n",
    "        ]\n",
    "        \n",
    "        self.up_layers_module_list = nn.ModuleList(self.up_layers)\n",
    "        \n",
    "        self.last_layer = OutLayer(in_channels=layer_sizes[1], out_channels=in_channels, device=device, dtype=dtype)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # print(f\"Unsqueezed input: \\n{x}\")        \n",
    "        \n",
    "        x = self.first_layer(x)\n",
    "        \n",
    "        # print(f\"First layer output: \\n{x}\")\n",
    "        \n",
    "        down_outputs = []\n",
    "        for down_layer in self.down_layers:\n",
    "            x = down_layer(x)\n",
    "            # print(f\"Down layer output: \\n{x.size()}\")\n",
    "            down_outputs.append(x)\n",
    "            \n",
    "        down_outputs_reversed = list(reversed(down_outputs))\n",
    "        \n",
    "        up_outputs = []\n",
    "        for (i, up_layer) in enumerate(self.up_layers):\n",
    "            x = up_layer(x, down_outputs_reversed[i + 1])\n",
    "            # print(f\"Up layer output: \\n{x.size()}\")\n",
    "            up_outputs.append(x)\n",
    "        \n",
    "        x = self.last_layer(x)\n",
    "        \n",
    "        # print(f\"Last layer output: \\n{x.size()}\")\n",
    "        \n",
    "        x = x.squeeze(0).squeeze(0)\n",
    "        \n",
    "        # print(f\"Squeezed output: \\n{x.size()}\")\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    torch.cuda.empty_cache()\n",
    "    dtype=torch.float32\n",
    "    \n",
    "    sequence_model = UNet1d(in_channels=1, device=device, dtype=dtype)\n",
    "    \n",
    "    loss_fn = nn.L1Loss()\n",
    "    # loss_fn = auraloss.time.SNRLoss()\n",
    "    # loss_fn = auraloss.freq.SumAndDifferenceSTFTLoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(params=sequence_model.parameters(), lr=0.01)\n",
    "\n",
    "    print(sequence_model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df1ff1b-b4ad-40cd-8f28-25f96a137175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c96e3-0eea-4897-a54b-8030dd3361e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:14:51.890339Z",
     "start_time": "2024-11-21T02:14:51.838712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.378890365362\t elapsed: 0:00:14.178621\tfiles_processed: 25\n",
      "Loss: 0.222374126315\t elapsed: 0:00:26.683783\tfiles_processed: 50\n",
      "Loss: 0.349628299475\t elapsed: 0:00:40.644103\tfiles_processed: 75\n",
      "Loss: 0.073013946414\t elapsed: 0:00:53.380538\tfiles_processed: 100\n",
      "Loss: 0.333045899868\t elapsed: 0:01:06.072085\tfiles_processed: 125\n",
      "Loss: 0.273125410080\t elapsed: 0:01:18.135365\tfiles_processed: 150\n",
      "Loss: 0.274757921696\t elapsed: 0:01:30.210839\tfiles_processed: 175\n",
      "Loss: 0.293407440186\t elapsed: 0:01:42.848867\tfiles_processed: 200\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Train\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "resample_rate = 48000\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    noisy_iter = iter(noisy_train)\n",
    "    clear_iter = iter(clear_train)\n",
    "    while time.time() - t0 < 60 * 5:\n",
    "        noisy_complete = next(noisy_iter, None)\n",
    "        if noisy_complete is None:\n",
    "            break\n",
    "        \n",
    "        noisy = noisy_complete[0].squeeze()\n",
    "        clear = next(clear_iter)[0].squeeze()\n",
    "\n",
    "        resampler = T.Resample(noisy_complete[1], resample_rate, dtype=torch.float32)\n",
    "        noisy = resampler(noisy)\n",
    "        clear = resampler(clear)\n",
    "\n",
    "        files_processed += 1\n",
    "        \n",
    "        noisy_split = torch.split(noisy, samples_per_batch)\n",
    "        clear_split = torch.split(clear, samples_per_batch)\n",
    "\n",
    "        loss_sum = 0\n",
    "        for split_idx, noisy_batch in enumerate(noisy_split):\n",
    "            # time1 = time.perf_counter()\n",
    "\n",
    "            noisy_batch = noisy_batch.to(device)\n",
    "            \n",
    "            noisy_pad = nn.ZeroPad1d((0, samples_per_batch - noisy_batch.size()[0]))\n",
    "            noisy_batch = noisy_pad(noisy_batch)\n",
    "            \n",
    "            clear_batch = clear_split[split_idx].to(device)\n",
    "            clear_pad = nn.ZeroPad1d((0, samples_per_batch - clear_batch.size()[0]))\n",
    "            clear_batch = clear_pad(clear_batch)\n",
    "\n",
    "            # time2 = time.perf_counter()\n",
    "            \n",
    "            sequence_model.train()\n",
    "\n",
    "            # time3 = time.perf_counter()\n",
    "            \n",
    "            prediction = sequence_model(noisy_batch)\n",
    "\n",
    "            # time4 = time.perf_counter()\n",
    "            \n",
    "            # prediction = torch.fft.ifft(sequence_model(torch.fft.fft(noisy_batch)))\n",
    "            loss = loss_fn(prediction, clear_batch)\n",
    "\n",
    "            if math.isnan(loss):\n",
    "                nan_in_prediction = \"Yes\" if torch.isnan(prediction).any() else \"No\"\n",
    "                print(f\"ERROR: NaN loss. NaN in prediction? {nan_in_prediction}\")\n",
    "                raise KeyboardInterrupt\n",
    "\n",
    "            # time5 = time.perf_counter()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # time6 = time.perf_counter()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # time7 = time.perf_counter()\n",
    "            # for name, param in sequence_model.named_parameters():\n",
    "            #     if param.grad is not None:\n",
    "            #         grad_mean = param.grad.mean().item()\n",
    "            #         grad_std = param.grad.std().item()\n",
    "            #         print(f\"{name}: grad_mean = {grad_mean}, grad_std = {grad_std}\")\n",
    "            #     else:\n",
    "            #         print(f\"No gradient for {name}\")\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            # time8 = time.perf_counter()\n",
    "            \n",
    "            sequence_model.eval()\n",
    "\n",
    "            # time9 = time.perf_counter()\n",
    "\n",
    "            loss_sum += loss\n",
    "        \n",
    "        if files_processed % 25 == 0:\n",
    "            elapsed_str = str(timedelta(seconds=time.time() - t0))\n",
    "            print(f\"Loss: {(loss_sum / 25.0):.12f}\\t elapsed: {elapsed_str}\\tfiles_processed: {files_processed}\")\n",
    "            loss_sum = 0\n",
    "            # 1-2: {(time2 - time1):.5f} 2-3: {(time3 - time2):.5f} 3-4: {(time4 - time3):.5f} 4-5: {(time5 - time4):.5f} 5-6: {(time6 - time5):.5f} 6-7: {(time7 - time6):.5f} 7-8: {(time8 - time7):.5f} 8-9: {(time9 - time8):.5f}\n",
    "\n",
    "    noisy_iter = iter(noisy_train)\n",
    "    clear_iter = iter(clear_train)\n",
    "\n",
    "    keep_going = True\n",
    "    while keep_going:\n",
    "        noisy_complete = next(noisy_iter)\n",
    "        noisy = noisy_complete[0].squeeze()\n",
    "        clear = next(clear_iter)[0].squeeze()\n",
    "        if noisy_complete[1] == 48000:\n",
    "            keep_going = False\n",
    "        else:\n",
    "            keep_going = True\n",
    "        \n",
    "    noisy_split = torch.split(noisy, samples_per_batch)\n",
    "    clear_split = torch.split(clear, samples_per_batch)\n",
    "\n",
    "    prediction_reconstructed = None\n",
    "    \n",
    "    for split_idx, noisy_batch in enumerate(noisy_split):\n",
    "        noisy_batch = noisy_batch.to(device)\n",
    "        \n",
    "        noisy_pad = nn.ZeroPad1d((0, samples_per_batch - noisy_batch.size()[0]))\n",
    "        noisy_batch = noisy_pad(noisy_batch)\n",
    "        \n",
    "        clear_batch = clear_split[split_idx].to(device)\n",
    "        clear_pad = nn.ZeroPad1d((0, samples_per_batch - clear_batch.size()[0]))\n",
    "        clear_batch = clear_pad(clear_batch)\n",
    "\n",
    "        # prediction = torch.fft.ifft(sequence_model(torch.fft.fft(noisy_batch)))\n",
    "        prediction = sequence_model(noisy_batch)\n",
    "        if prediction_reconstructed is not None:\n",
    "            prediction_reconstructed = torch.cat((prediction_reconstructed, prediction))\n",
    "        else:\n",
    "            prediction_reconstructed = prediction\n",
    "\n",
    "    print(noisy.size())\n",
    "    print(prediction_reconstructed.size())\n",
    "    print(clear.size())\n",
    "\n",
    "    print(prediction_reconstructed)\n",
    "\n",
    "    torch.save(sequence_model, models_dir + f\"/model-{time.strftime(\"%Y%m%d-%H%M%S\")}\")\n",
    "\n",
    "    display(Audio(noisy.cpu().detach(), rate=48000))\n",
    "    display(Audio(prediction_reconstructed.cpu().detach(), rate=48000))\n",
    "    display(Audio(clear.cpu().detach(), rate=48000))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca8bcf-9a45-4704-bd4c-f1e38de1ca1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539d6cf-6398-4e33-85ec-daa79c3113fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
